{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YOwinUSrWR1"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/torresmateo/penguin-tf-workshop/blob/master/D3_2_Clasificacion_sarcasmo.ipynb\" target=\"_parent\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Detección de Sarcasmo en Títulos de noticias\n",
    "\n",
    "Un ejemplo interesante de clasificación de texto es la detección de sarcasmo en títulos de noticias. El [dataset](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection) está disponible en Kaggle, sin embargo este código provee código para descargarlo de forma automática si estás usando Google Colab.\n",
    "\n",
    "Primero que nada, importamos las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w-OYabivmrFz",
    "outputId": "430431e7-bb7f-44da-e833-91d5b8a86b6e"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# para disminuir la cantidad de código a escribir, importamos \n",
    "# el Tokenizer y pad_sequences de forma directa\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "import gdown\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nzr8KKEBsBcd"
   },
   "source": [
    "Bajamos los datos y guardamos la ubicación del archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "pytmseH-sEa3",
    "outputId": "722ee01e-97c6-4ac6-efae-12cce9b55ce2"
   },
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://drive.google.com/uc?id=1MF0nvMJyr62S8PwKFfVAVVIxybxSyMa8'\n",
    "output = '/tmp/sarcasm.json'\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cx6W-yvYsV4k"
   },
   "source": [
    "Cargamos los datos del dataset a una lista de oraciones y sus labels respectivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dA-_1q6gsUBq"
   },
   "outputs": [],
   "source": [
    "with open(\"/tmp/sarcasm.json\", 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "oraciones = []\n",
    "labels = []\n",
    "\n",
    "for ejemplo in dataset:\n",
    "    oraciones.append(ejemplo['headline'])\n",
    "    labels.append(ejemplo['is_sarcastic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oEKbgBE_ujCf"
   },
   "source": [
    "exploramos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "43aaJEyesiYA",
    "outputId": "7223362f-8eb5-432c-ad3e-6352e4d6a3d2"
   },
   "outputs": [],
   "source": [
    "print('Cnatidad de ejemplos en el dataset:',len(oraciones))\n",
    "print(f'Primeros ejemplos del dataset:')\n",
    "for i in range(5):\n",
    "    print(f'\\n\\t{oraciones[i]} \\n\\t\\tEs sarcasmo? {labels[i]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IFWEVshuvYFn"
   },
   "source": [
    "# Partir el dataset\n",
    "\n",
    "Distribuimos el dataset en testing y training. Como vimos arriva, hay 28619 ejemplos. Podemos usar 20000 ejemplos para training (cerca del 70%), y los restantes 8619 para testing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gz2ZBrHPtwx-"
   },
   "outputs": [],
   "source": [
    "particion = 20000\n",
    "\n",
    "oraciones_train = oraciones[0:particion]\n",
    "oraciones_test = oraciones[particion:]\n",
    "labels_train = np.array(labels[0:particion])\n",
    "labels_test = np.array(labels[particion:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ixZoxBQwEPa"
   },
   "source": [
    "# Codificar el texto. \n",
    "\n",
    "Ahora usamos el tokenizer para codificar el texto a una forma numérica. \n",
    "\n",
    "Siempre se debe tener en cuenta que se asume que no tenemos acceso a los datos de testing, por lo cual es importante definir el *out of value token* y ejecutar `fit_on_texts` solo en el *training set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3-RQ1tqvi2n"
   },
   "outputs": [],
   "source": [
    "# establecemos el límite de palabras que se usan a 10000 \n",
    "# (un número razonable, que debería contener a las palabras\n",
    "#  más comunes del inglés.)\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<???>')\n",
    "\n",
    "# aprendemos el vocabulario\n",
    "tokenizer.fit_on_texts(oraciones_train)\n",
    "vocabulario = tokenizer.word_index\n",
    "\n",
    "# transformamos el training set a secuencias\n",
    "sec_train = tokenizer.texts_to_sequences(oraciones_train)\n",
    "\n",
    "# hacemos el padding de las secuencias \n",
    "# (100 debería bastar para la mayoría de los titulares)\n",
    "# indicamos que se ignoren las palabras posteriores, y que los ceros\n",
    "# se agreguen al final de las secuencias.\n",
    "pad_train = pad_sequences(sec_train, maxlen=100, padding='post', truncating='post')\n",
    "\n",
    "# procesamos el testing set de manera similar\n",
    "sec_test = tokenizer.texts_to_sequences(oraciones_test)\n",
    "pad_test = pad_sequences(sec_test, maxlen=100, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uHPdBnzS0RwO"
   },
   "source": [
    "# Creamos la red neuronal\n",
    "\n",
    "Creamos y compilamos nuestro clasificador\n",
    "\n",
    "Aquí, se introducen dos nuevos tipos de *layer*: \n",
    "\n",
    "1. *Embedding* layer, que construirá vectores a partir de nuestros ejemplos. Si leemos la [documentación](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) vemos dos parámetros importantes:\n",
    "  * `input_dim`: el tamaño del vocabulario\n",
    "  * `output_dim`: la dimensión del vector creado por el layer.\n",
    "\n",
    "2. [`GlobalAveragePooling1D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling1D), funciona de forma similar a los demás tipos de pooling. Vea el resumen del modelo para entender el efecto de este layer sobre los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jx3t-4jbz-g0"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 16, input_length=100),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMBlR48o3QsE"
   },
   "source": [
    "para entender un poco mejor el modelo con los nuevos layers, podemos ver un resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "qmXvBBlr3QEX",
    "outputId": "7ae0c619-6cb3-41c4-f1c5-d247c98142e0"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xb2tQCjW3cT5"
   },
   "source": [
    "Entrenamos el modelo como siempre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JHfVwMp93Uie",
    "outputId": "fd869b49-ef07-48f3-836d-d3b99e3d5f6d"
   },
   "outputs": [],
   "source": [
    "historia = model.fit(pad_train, labels_train, epochs=30, validation_data=(pad_test, labels_test), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RgNR9Bk34a-n"
   },
   "source": [
    "copio la función de la clase pasada para ver la evolución de nuestros resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BtD_hcux3sck"
   },
   "outputs": [],
   "source": [
    "def ver_historia(historia, titulo = '', ax = None):\n",
    "    \"\"\"\n",
    "    Visualizar una la historia de un modelo, \n",
    "    se hará una figura que muestre la evolución de la\n",
    "    función de costo y de la precisión del modelo con\n",
    "    respecto a los epochs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    historia : keras History\n",
    "        Es lo que retorna la llamada a `model.fit`\n",
    "    titulo : str\n",
    "        el título del ax de arriba\n",
    "    ax : np.array\n",
    "        si se provee, no se creará una imagen nueva y se usará\n",
    "        `ax` en su lugar. Se debe proveer 2 ejes de una figura\n",
    "        de pyplot.\n",
    "    \"\"\"\n",
    "    create = ax is None\n",
    "    if create:\n",
    "        fig, ax = plt.subplots(2,1,figsize=(10,8), dpi=100)\n",
    "    acc      = historia.history['accuracy']\n",
    "    val_acc  = historia.history['val_accuracy']\n",
    "    loss     = historia.history['loss']\n",
    "    val_loss = historia.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    ax[0].grid(True)\n",
    "    ax[0].plot(epochs, acc, label=f\"Entrenamiento - {titulo}\")\n",
    "    ax[0].plot(epochs, val_acc, label=f\"Evaluación - {titulo}\")\n",
    "    ax[0].set_ylabel('Precisión')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    #ax[0].set_ylim(0, 1.1)\n",
    "    ax[0].legend()\n",
    "    ax[1].grid(True)\n",
    "    ax[1].plot(epochs, loss, label=f\"Entrenamiento - {titulo}\")\n",
    "    ax[1].plot(epochs, val_loss, label=f\"Evaluación - {titulo}\")\n",
    "    ax[1].set_ylabel('Costo')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend()\n",
    "    if create:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "colab_type": "code",
    "id": "HVzT4SqC4gI7",
    "outputId": "d998a60e-f460-4987-a20d-53ec1926f1a0"
   },
   "outputs": [],
   "source": [
    "ver_historia(historia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvieiRac6sXT"
   },
   "source": [
    "Vemos que nuestro modelo no es muy bueno para generalizar las predicciones en este dataset. tenemos más o menos 80% de precisión luego de entrenar por 30 *epochs*. \n",
    "\n",
    "# TAREA (para la casa)\n",
    "\n",
    "Este modelo es capaz de obtener mucho mejor precisión que lo que vimos luego de los 30 *epochs*. El ejercicio consiste en modificar los parámetros de nuestro modelo y nuestro tokenizador:\n",
    "\n",
    "* la cantidad de palabras en el vocabulario\n",
    "* la longitud máxima del *padding*\n",
    "* las dimensiones del *embedding*\n",
    "* etc.\n",
    "\n",
    "Modifique estos valores y vaya explorando diferentes combinaciones para lograr una precisión del 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Créditos \n",
    "\n",
    "Este notebook utiliza y modifica contenido del curso online [TensorFlow in Practice](https://www.deeplearning.ai/tensorflow-in-practice/)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "D3_2_Clasificacion_sarcasmo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
